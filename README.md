# Agentic Chat Application

A synergistic conversational agent built with **LangGraph** and **FastAPI**, designed to answer queries about SynergisticIT training programs and general topics with robust guardrails, intelligent routing, and caching.

## Key Features

-   **Agentic Workflow**: Uses LangGraph to orchestrate a sophisticated decision-making pipeline (Router -> Retriever -> Grader -> Generator).
-   **Smart Routing**: Classifies user intent (Financing, Placement, Curriculum, etc.) and targets specific knowledge bases.
-   **Query Rewriting**: Transforms vague user inputs (e.g., "cost?") into optimized search queries ("What is the tuition cost...?").
-   **Redis Caching**: Caches answers for identical questions to reduce latency and API costs.
    -   *Graceful Fallback*: Automatically disables caching if Redis is not available.
-   **Robust Guardrails**: Filters out toxic, irrelevant, or unsafe queries before they reach the LLM.
-   **LangSmith Tracing**: Integrated tracing for debugging and monitoring LLM chains and graph execution.
-   **Multi-Layered Knowledge Base**:
    -   Decision FAQ (Atomic Q&A)
    -   Policy Documents (Refunds, ISA)
    -   Program Details & Trust (Web Scraped Content)

## Project Structure

```
src/
├── api.py              # FastAPI server entry point
├── config.py           # Configuration & Environment Variables
├── ingest.py           # Knowledge Base Ingestion Script
├── main.py             # CLI Chat Interface
├── graph/
│   ├── workflow.py     # LangGraph State Machine Definition
│   ├── state.py        # AgentState Type Definition
│   └── nodes/          # Concept-Specific Logic modules
│       ├── router.py
│       ├── retriever.py
│       ├── grader.py
│       ├── generator.py
│       ├── query_rewriter.py
│       └── input_guardrails.py
├── ingestion/          # Data Processing Modules
│   ├── scraper.py
│   ├── processor.py
│   ├── chunker.py
│   └── vector_db.py
└── utils/
    └── cache.py        # Redis Cache Manager
```

## Setup

### 1. Prerequisites
-   **Python 3.10+**
-   **Docker Desktop** (for Redis)

### 2. Install Dependencies
```bash
# Create and activate virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows

# Install requirements
pip install -r requirements.txt
```

### 3. Environment Variables
Create a `.env` file in the project root:

```ini
# OpenAI
OPENAI_API_KEY=your_api_key_here

# Redis (Optional, defaults to localhost)
REDIS_URL=redis://localhost:6379/0

# LangSmith Tracing (Optional but recommended)
LANGCHAIN_TRACING=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_API_KEY=your_langsmith_key
LANGCHAIN_PROJECT="Agentic Chat Application"
```

### 4. Infrastructure (Redis)
Start the Redis server using Docker:
```bash
docker run -d -p 6379:6379 --name redis-server redis
```
Verify connection:
```bash
docker exec -it redis-server redis-cli ping
# Output: PONG
```

### 5. Ingest Knowledge Base
(First run only)
```bash
python src/ingest.py
```

## Usage

### Run API Server
Start the FastAPI server:
```bash
python src/api.py
```
The API will be available at `http://localhost:8000`.
-   **Docs**: `http://localhost:8000/docs`
-   **Chat Endpoint**: `POST /chat`

### Run CLI Interface
For testing locally in the terminal:
```bash
python src/main.py
```

## LangSmith Traceability

This project uses **LangSmith** to trace and monitor the execution of the agent. This allows you to:
-   **Debug** complex chains and graph transitions.
-   **Analyze** latency and token usage for each step (Router, Retriever, etc.).
-   **Inspect** input/output for every node in the LangGraph.

### How to Enable
1.  Sign up for a LangSmith account at [smith.langchain.com](https://smith.langchain.com/).
2.  Generate an API Key.
3.  Set the environment variables in `.env` as shown in the **Setup** section.

### Viewing Traces
Once enabled, every request to the chat API will be logged to your LangSmith project ("Agentic Chat Application"). You can view the traces to see:
-   The exact prompt sent to the LLM by the `router`.
-   The documents retrieved by the `retriever`.
-   The grading decision made by the `grader`.
-   The final answer generated by the `generator`.

## API Endpoints

### `POST /chat`

Interact with the agent.

**Request Body**:
```json
{
  "question": "What courses do you offer?"
}
```

**Response**:
```json
{
  "answer": "SynergisticIT offers courses in Java, Python, Data Science, AWS, and more...",
  "relevance_score": "3/3"
}
```
